= Monitor Application Health
:navtitle: Monitor Application Health

_25 MINUTE EXERCISE_

In this section we will learn how to monitor application health using OpenShift
health probes and how you can see container resource consumption using metrics.

[sidebar]
.OpenShift Health Probes
--

When building microservices, monitoring becomes of extreme importance to make sure all services
are running at all times, and when they don't there are automatic actions triggered to rectify
the issues.

OpenShift, using Kubernetes health probes, offers a solution for monitoring application
health and trying to automatically heal faulty containers through restarting them to fix issues such as
a deadlock in the application which can be resolved by restarting the container. Restarting a container
in such a state can help to make the application more available despite bugs.

Furthermore, there are of course a category of issues that can't be resolved by restarting the container.
In those scenarios, OpenShift would remove the faulty container from the built-in load-balancer and send traffic
only to the healthy containers that remain.

There are three types of health probes available in OpenShift: https://docs.openshift.com/container-platform/4.10/applications/application-health.html#application-health-about_application-health[startup, readiness and liveness probes^].

* **Startup probes** determine if the container in which it is scheduled is started
* **Readiness probes** determine if the container in which it is scheduled is ready to service requests
* **Liveness probes** determine if the container in which it is scheduled is still running


Health probes also provide crucial benefits when automating deployments with practices like rolling updates in
order to remove downtime during deployments. A readiness health probe would signal OpenShift when to switch
traffic from the old version of the container to the new version so that the users don't get affected during
deployments.

There are https://docs.openshift.com/container-platform/4.10/applications/application-health.html#application-health-about_types_application-health[three ways to define a health probe^] for a container:

* **HTTP Checks:** healthiness of the container is determined based on the response code of an HTTP
endpoint. Anything between 200 and 399 is considered success. A HTTP check is ideal for applications
that return HTTP status codes when completely initialized.

* **Container Execution Checks:** a specified command is executed inside the container and the healthiness is
determined based on the return value (0 is success).

* **TCP Socket Checks:** a socket is opened on a specified port to the container and it's considered healthy
only if the check can establish a connection. TCP socket check is ideal for applications that do not
start listening until initialization is complete.
--

[#understanding_liveness]
==  Understanding Liveness Probes

**What happens if you DON'T setup Liveness checks?**

Imagine the _Node.js Web Service_ is stuck in a state (Blocked event loop, Out of Memory, etc.)
where it cannot perform as it should. Let's access inside the container and simulate this state.

In the OpenShift Web Console, from the **Developer view**,
`*click on 'Topology' -> '(D) web-nodejs-git' -> 'Resources' -> '(P) web-nodejs-git-x-xxxxx'*`

image::openshift-nodejs-pod.png[OpenShift Node.js Service Pod, 700]

Then, `*from the Terminal tab, run the following command*`:

[.console-input]
[source,bash,subs="{markup-in-source}"]
----
curl http://web-nodejs-git:8080/boom
----

image::openshift-nodejs-service-boom.png[OpenShift Node.js Service Boom, 700]

You just triggered an issue in the _Node.js Web Service_ process that simulates an event-loop delay.

In the OpenShift Web Console, `*click on the 'Events' and 'Logs' tabs*` and notice that everything **seems** to be OK.

image::openshift-nodejs-events.png[OpenShift Node.js Service Events, 500]

image::openshift-nodejs-logs.png[OpenShift Node.js Service Logs, 500]

Now, try to access your _Node.js Web Service_ using the Route URL.
The UI should load **very slowly**, as the process was forced into a broken state when you used `curl` on the `/boom` endpoint. You can see that the response times from the Node.js service are elevated using the DevTools in your browser, if you want.

image::openshift-nodejs-app-network-logs.png[OpenShift Node.js DevTools Log]

Often, applications need a restart to work correctly again.

In the OpenShift Web Console, `*click on 'Actions' -> 'Delete Pod' -> 'Delete'*`

image::openshift-nodejs-delete-pod.png[OpenShift Node.js Service Delete Pod, 700]

A new instance (pod) will be redeployed. 

The _Node.js Web Service_ will be in a healthy state again.

To make your application more robust and reliable, a **Liveness check**  will be used to check
if the container itself has become unresponsive. If the container cannot respond to the liveness probe due to a condition such as a deadlock,
the container could automatically restart (based on its restart policy).

[#configuring_liveness]
== Configuring Liveness Probes

https://github.com/nodeshift-archived/kube-probe[Kube Probe^] is a Node.js module that allows applications to provide information about their state to external viewers. This is typically useful
in cloud environments where automated processes must be able to determine whether the application should be discarded or restarted.
This extension is already present in the Node.js microservice and you can check that by accessing the path `/api/health/liveness` under the URL of the Route associated 
to it:

image::openshift-nodejs-health-endpoint.png[Health endpoint, 700]

It should return the following response:

[source,json,subs="{markup-in-source}"]
----
OK
----

In the OpenShift Web Console, from the **Developer view**,
`*click on 'Topology' -> '(D) nodejs-web-git' -> 'Actions ->'Edit Health Checks'*`.

image::openshift-nodejs-edit-health-check.png[Node.js Service Edit Health Check, 500]

Then `*click on 'Add Liveness Probe'*`

image::openshift-nodejs-liveness-added.png[Change Liveness Probe, 500]

This will open the editing dialog as seen below:

image::openshift-nodejs-add-liveness-probe.png[Inventory Edit Liveness Probe, 500]

`*Enter the following information:*`

.Liveness Probe
[%header,cols=2*]
|===
|Parameter
|Value

|Type
|HTTP GET

|Use HTTPS
|_Unchecked_

|HTTP Headers
|_Empty_

|Path
|/api/health/liveness

|Port
|8080

|Failure Threshold
|3

|Success Threshold
|1

|Initial Delay
|10

|Period
|10

|Timeout
|1

|===

`*Click on the check icon*` in the lower right corner of the liveness edit dialog to apply the changes for the liveness probe.

image::openshift-inventory-check-apply-liveness.png[Apply Liveness Probe, 200]


[IMPORTANT]
====
When you added the Liveness probe, a Readiness probe was also added automatically. Since you haven't configured the Readiness probe, delete it using the minus (`-`) icon _before_ clicking the *Save* button.

image::openshift-inventory-remove-readiness-probe.png[Remove Readiness Probe, 600]

====



Finally `*click the 'Save' button*`. OpenShift automates deployments using
https://docs.openshift.com/container-platform/4.10/welcome/index.html[deployment triggers^]
that react to changes to the container image or configuration.
Therefore, as soon as you define the probe, OpenShift automatically redeploys the pod using the new configuration including the liveness probe.

[#testing_liveness]
== Testing Liveness Probes

As you did previously, in the OpenShift Web Console, from the **Developer view**, access the container and break the _Node.js Web Service_ process using the `curl http://web-nodejs-git:8080/boom` command.

Then, still in the OpenShift Web Console, `*click on the 'Events' tab*`.

After 3 failed checks, OpenShift automatically restarts the container. This is because the `/api/health/liveness` endpoint can no longer respond within the 1 second threshold configured in the liveness probe.

image::openshift-nodejs-events-failed-check.png[OpenShift Node.js Service Event Failed Check]


[#understanding_readiness]
==  Understanding Readiness Probes

What happens if you DON'T setup Readiness checks? Let's simulate traffic to the _Catalog Service_ to find out.

. Execute the following command in the `>_` terminal window:
+
[.console-input]
[source,bash,subs="{markup-in-source}"]
----
for i in {1..60}
do 
    if curl -s -o /dev/null http://catalog-spring-boot:8080/actuator/health;
    then 
        MSG="\033[0;32mThe request to Catalog Service has succeeded\033[0m"
    else 
        MSG="\033[0;31mERROR - The request to Catalog Service has failed\033[0m" 
    fi
    
    echo -e $MSG
    sleep 1s
done
----
. You should see output similar to this:
+
image::che-catalog-traffic-ok.png[Catalog Traffic OK, 500]
. Scale out your _Catalog Service_ to 2 instances:
    * Open the **Developer** perspective in the OpenShift Web Console.
    * Click on Topology in the side-menu.
    * Select the _catalog-spring-boot_ by clicking it's node in the Topology view.
    * Switch to the *Details* tab, then click once on the up arrow on the right side of the blue Pod circle.
+
image::openshift-scale-out-catalog.png[OpenShift Scale Out Catalog, 700]
. You should see the 2 instances (Pods) running.
. Now, observe the `>_` terminal window and the output of the `curl` command loop:
+
image::che-catalog-traffic-ko.png[Catalog Traffic KO]

Notice how some of the requests failed? This is because traffic is sent to the new Pod as soon it is created, even if the application is not ready to accept traffic. Since the _Catalog Service_ takes up to 20 seconds to start up, traffic that reaches the new Pod during that start up period will fail to receive a response.

A **Readiness Probe** is required to prevent this from happening. The status returned by a readiness probe determines if the container which it targets can service incoming requests.
If the readiness probe fails for a given Pod, the endpoints controller ensures the container has its IP address removed from the endpoints of all services.
A readiness probe can be used to signal to the endpoints controller that even though a container is running, it should not receive any traffic from a proxy.

[#configuring_readiness]
==  Configuring Readiness Probes

First, scale down your _Catalog Service_ to 1 instance. In the OpenShift Web Console, from the **Developer view**,
`*click on 'Topology' -> '(D) catalog-spring-boot' -> 'Details' then click once on the down arrows
on the right side of the pod blue circle*`.

http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#production-ready[Spring Boot Actuator^] is a
sub-project of Spring Boot which adds health and management HTTP endpoints to the application. Enabling Spring Boot
Actuator is done via adding **org.springframework.boot:spring-boot-starter-actuator** dependency to the Maven project
dependencies which is already done for the _Catalog Service_.

Verify that the health endpoint works for the _Catalog Service_:

. Find the _Catalog Service_ node in the Topology View in the OpenShift Web Console.
. Click on the **Open URL** icon associated with the _Catalog Service_. This will open a new tab that displays a default homepage for the _Catalog Service_.
+
image::monitoring-open-catalog-url.png[Open URL icon for the Catalog Service]
. Append `/actuator/health` to the _Catalog Service_ URL in your web-browser's address bar. This should return a JSON response as shown:
+
image::actuator-endpoint.png[Actuator endpoint, 700]

This endpoint can be used by a **Readiness Probe** to determine that the service is ready to accept incoming HTTP requests.

In the OpenShift Web Console, from the **Developer view**,
`*click on 'Topology' -> '(D) catalog-spring-boot' -> 'Add Health Checks'*`.

image::openshift-catalog-add-health-check.png[Catalog Add Health Check, 700]

Then `*click on 'Add Readiness Probe'*`

image::openshift-catalog-add-readiness-probe.png[Catalog Add Readiness Probe, 600]

`*Enter the following information:*`

.Readiness Probe
[%header,cols=2*]
|===
|Parameter
|Value

|Type
|HTTP GET

|Use HTTPS
|_Unchecked_

|HTTP Headers
|_Empty_

|Path
|/actuator/health

|Port
|8080

|Failure Threshold
|3

|Success Threshold
|1

|Initial Delay
|0

|Period
|10

|Timeout
|1

|===

Finally `*click on the check icon and the 'Add' button*`. The Readiness check is now set up.

[#testing_Readiness]
== Testing Readiness Probes

Now let's test it as you did previously.
`*Generate traffic to  Catalog Service*` and then, in the OpenShift Web Console,
`*scale out the Catalog Service to 2 instances (pods)*`

You should not see any error means that you can now **scale out your _Catalog Service_ with no downtime.**

[#understanding_startup]
==  Understanding Startup Probes

**Startup probes** are similar to liveness probes but only executed at startup.
When a startup probe is configured, the other probes are disabled until it suceeds.

Sometimes, some (legacy) applications might need extra times for their first initialization.
In such cases, setting a longer liveness internal might compromise the main benefit of this probe ie providing
the fast response to stuck states.

**Startup probes** are useful to cover this worse case startup time.

[#monitoring_all_applications]
== Monitoring All Application Healths

Now you understand and know how to configure Readiness, Liveness and Startup probes, let's confirm your expertise!

`*Configure the remaining Probes for the Inventory and Catalog Services*` using the following information:

[%header,cols=3*]
|===
|Inventory Service
|Readiness
|Startup

|Type
|HTTP GET
|HTTP GET

|Use HTTPS
|_Unchecked_
|_Unchecked_

|HTTP Headers
|_Empty_
|_Empty_

|Path
|/q/health/ready
|/q/health/live

|Port
|8080
|8080

|Failure Threshold
|3
|3

|Success Threshold
|1
|1

|Initial Delay
|0
|0

|Period
|5
|5

|Timeout
|1
|1

|===

[%header,cols=3*]
|===
|Catalog Service
|Liveness
|Startup

|Type
|HTTP GET
|HTTP GET

|Use HTTPS
|_Unchecked_
|_Unchecked_

|HTTP Headers
|_Empty_
|_Empty_

|Path
|/actuator/health
|/actuator/health

|Port
|8080
|8080

|Failure Threshold
|3
|15

|Success Threshold
|1
|1

|Initial Delay
|0
|0

|Period
|5
|10

|Timeout
|1
|1

|===

[#monitoring_application_metrics]
== Monitoring Applications Metrics

Metrics are another important aspect of monitoring applications which is required in order to
gain visibility into how the application behaves and particularly in identifying issues.

OpenShift provides container metrics out-of-the-box and displays how much memory, cpu and network
each container has been consuming over time.

In the  OpenShift Web Console, from the **Developer view**,
`*click on 'Observe'*`.

In the dashboard, you can see the different **Resource Usage** sections.
`*click on one graph to get more details*`.

image::openshift-monitoring.png[OpenShift Monitoring,740]

From the **Developer view**, `*click on 'Topology' -> any Deployment (D) and click on the associated Pod (P)*`

In the pod overview, you can see a more detailed view of the pod consumption.
The graphs can be found under the Metrics heading, or Details in earlier versions of the OpenShift console.

image::openshift-pod-details.png[OpenShift Pod Details,740]

Well done! You have completed this lab.